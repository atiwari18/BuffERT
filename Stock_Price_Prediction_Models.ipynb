{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "22386da1",
      "metadata": {
        "id": "22386da1"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Config\n",
        "selected_tickers = ['ABBV', 'ADBE', 'ADI', 'ABNB', 'ZTS', 'XOM', 'JNJ', 'ACN', 'CMCSA', 'LMT', 'MSFT', 'AAPL', 'GOOGL', 'AMZN', 'TSLA']\n",
        "SEQ_LEN = 30\n",
        "FEATURE_COLUMNS = ['Close', 'Return', 'MA7', 'MA14', 'MA30', 'RSI', 'MACD', 'Signal_Line', 'Rolling_Volatility']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "7876e32a",
      "metadata": {
        "id": "7876e32a"
      },
      "outputs": [],
      "source": [
        "# Helper functions\n",
        "def compute_rsi(series, window=14):\n",
        "    delta = series.diff()\n",
        "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
        "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
        "    rs = gain / loss\n",
        "    rsi = 100 - (100 / (1 + rs))\n",
        "    return rsi\n",
        "\n",
        "\n",
        "def compute_macd(series, short_window=12, long_window=26, signal_window=9):\n",
        "    short_ema = series.ewm(span=short_window, adjust=False).mean()\n",
        "    long_ema = series.ewm(span=long_window, adjust=False).mean()\n",
        "    macd = short_ema - long_ema\n",
        "    signal = macd.ewm(span=signal_window, adjust=False).mean()\n",
        "    return macd, signal\n",
        "\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, gamma=2.0):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.gamma = gamma\n",
        "        self.ce = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        ce_loss = self.ce(inputs, targets)\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        return (1 - pt) ** self.gamma * ce_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d381144b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d381144b",
        "outputId": "570dfe5d-476b-4c00-93fa-20f74f4c663b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  15 of 15 completed\n",
            "<ipython-input-11-8ad1c1af6892>:20: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[FEATURE_COLUMNS] = scaler.fit_transform(df[FEATURE_COLUMNS])\n"
          ]
        }
      ],
      "source": [
        "# Data download and preprocessing\n",
        "raw_data = yf.download(selected_tickers, period='3y', interval='1d')['Close']\n",
        "\n",
        "feature_data = {}\n",
        "scaler = StandardScaler()\n",
        "\n",
        "for ticker in selected_tickers:\n",
        "    df = pd.DataFrame({'Close': raw_data[ticker]})\n",
        "    df['Return'] = df['Close'].pct_change()\n",
        "    df['MA7'] = df['Close'].rolling(window=7).mean()\n",
        "    df['MA14'] = df['Close'].rolling(window=14).mean()\n",
        "    df['MA30'] = df['Close'].rolling(window=30).mean()\n",
        "    df['RSI'] = compute_rsi(df['Close'])\n",
        "    df['MACD'], df['Signal_Line'] = compute_macd(df['Close'])\n",
        "    df['Rolling_Volatility'] = df['Return'].rolling(window=30).std()\n",
        "    df['Label_Next_Day'] = (df['Close'].shift(-1) > df['Close']).astype(int)\n",
        "    df['Label_Next_Week'] = (df['Close'].shift(-5) > df['Close']).astype(int)\n",
        "    df['Label_Next_Month'] = (df['Close'].shift(-20) > df['Close']).astype(int)\n",
        "    df = df.dropna()\n",
        "    df[FEATURE_COLUMNS] = scaler.fit_transform(df[FEATURE_COLUMNS])\n",
        "    feature_data[ticker] = df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "12f299ac",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12f299ac",
        "outputId": "9efc32df-2f33-4648-8453-64e2fe7368a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10 - Train Loss: 0.3983 - Val Loss: 0.4001 - LR: 0.000100\n",
            "Epoch 20 - Train Loss: 0.3110 - Val Loss: 0.3669 - LR: 0.000100\n",
            "Epoch 30 - Train Loss: 0.2614 - Val Loss: 0.3413 - LR: 0.000100\n",
            "Early stopping at epoch 36\n",
            "\n",
            "=== Transformer Final Test Results ===\n",
            "Next Day   - Acc: 0.5775, Prec: 0.6060, Rec: 0.5529, F1: 0.5782\n",
            "Next Week  - Acc: 0.7310, Prec: 0.7749, Rec: 0.7067, F1: 0.7393\n",
            "Next Month - Acc: 0.8592, Prec: 0.8673, Rec: 0.8698, F1: 0.8685\n"
          ]
        }
      ],
      "source": [
        "# Transformer Model\n",
        "class StockTransformerMultiTask(nn.Module):\n",
        "    def __init__(self, feature_size, hidden_dim=128, num_classes=2, nhead=4, num_layers=4):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Linear(feature_size, hidden_dim)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=nhead, batch_first=True, dropout=0.2)\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.fc_day = nn.Linear(hidden_dim, num_classes)\n",
        "        self.fc_week = nn.Linear(hidden_dim, num_classes)\n",
        "        self.fc_month = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = self.transformer(x)\n",
        "        x = x.mean(dim=1)\n",
        "        return self.fc_day(x), self.fc_week(x), self.fc_month(x)\n",
        "\n",
        "# Prepare Dataset\n",
        "X_all, y_all_day, y_all_week, y_all_month = [], [], [], []\n",
        "\n",
        "for ticker, df in feature_data.items():\n",
        "    for i in range(SEQ_LEN, len(df) - 20):\n",
        "        seq_x = df.iloc[i-SEQ_LEN:i][FEATURE_COLUMNS].values\n",
        "        X_all.append(seq_x)\n",
        "        y_all_day.append(df.iloc[i]['Label_Next_Day'])\n",
        "        y_all_week.append(df.iloc[i]['Label_Next_Week'])\n",
        "        y_all_month.append(df.iloc[i]['Label_Next_Month'])\n",
        "\n",
        "X_all = np.array(X_all)\n",
        "y_all_day = np.array(y_all_day)\n",
        "y_all_week = np.array(y_all_week)\n",
        "y_all_month = np.array(y_all_month)\n",
        "\n",
        "X_temp, X_test, y_temp_day, y_test_day, y_temp_week, y_test_week, y_temp_month, y_test_month = train_test_split(\n",
        "    X_all, y_all_day, y_all_week, y_all_month, test_size=0.1, shuffle=True, random_state=42)\n",
        "\n",
        "X_train, X_val, y_train_day, y_val_day, y_train_week, y_val_week, y_train_month, y_val_month = train_test_split(\n",
        "    X_temp, y_temp_day, y_temp_week, y_temp_month, test_size=0.1111, shuffle=True, random_state=42)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
        "X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
        "y_train_day = torch.tensor(y_train_day, dtype=torch.long).to(device)\n",
        "y_val_day = torch.tensor(y_val_day, dtype=torch.long).to(device)\n",
        "y_test_day = torch.tensor(y_test_day, dtype=torch.long).to(device)\n",
        "y_train_week = torch.tensor(y_train_week, dtype=torch.long).to(device)\n",
        "y_val_week = torch.tensor(y_val_week, dtype=torch.long).to(device)\n",
        "y_test_week = torch.tensor(y_test_week, dtype=torch.long).to(device)\n",
        "y_train_month = torch.tensor(y_train_month, dtype=torch.long).to(device)\n",
        "y_val_month = torch.tensor(y_val_month, dtype=torch.long).to(device)\n",
        "y_test_month = torch.tensor(y_test_month, dtype=torch.long).to(device)\n",
        "\n",
        "train_dataset = TensorDataset(X_train, y_train_day, y_train_week, y_train_month)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Train Transformer\n",
        "model = StockTransformerMultiTask(feature_size=X_train.shape[2]).to(device)\n",
        "criterion = FocalLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
        "\n",
        "EPOCHS = 200\n",
        "best_val_loss = np.inf\n",
        "patience = 10\n",
        "trigger_times = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for data, targets_day, targets_week, targets_month in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        out_day, out_week, out_month = model(data)\n",
        "        loss = criterion(out_day, targets_day) + criterion(out_week, targets_week) + criterion(out_month, targets_month)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_day, val_week, val_month = model(X_val)\n",
        "        val_loss = criterion(val_day, y_val_day) + criterion(val_week, y_val_week) + criterion(val_month, y_val_month)\n",
        "\n",
        "    scheduler.step(val_loss)\n",
        "    avg_train_loss = running_loss / len(train_loader)\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        trigger_times = 0\n",
        "        best_model_state = model.state_dict()\n",
        "    else:\n",
        "        trigger_times += 1\n",
        "        if trigger_times >= patience:\n",
        "            print(f\"Early stopping at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        current_lr = scheduler.optimizer.param_groups[0]['lr']\n",
        "        print(f\"Epoch {epoch+1} - Train Loss: {avg_train_loss:.4f} - Val Loss: {val_loss:.4f} - LR: {current_lr:.6f}\")\n",
        "\n",
        "model.load_state_dict(best_model_state)\n",
        "\n",
        "# Evaluation\n",
        "def evaluate(preds, targets):\n",
        "    preds = preds.argmax(dim=1).cpu().numpy()\n",
        "    targets = targets.cpu().numpy()\n",
        "    return accuracy_score(targets, preds), precision_score(targets, preds, zero_division=0), recall_score(targets, preds, zero_division=0), f1_score(targets, preds, zero_division=0)\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    preds_day, preds_week, preds_month = model(X_test)\n",
        "\n",
        "metrics_day = evaluate(preds_day, y_test_day)\n",
        "metrics_week = evaluate(preds_week, y_test_week)\n",
        "metrics_month = evaluate(preds_month, y_test_month)\n",
        "\n",
        "print(\"\\n=== Transformer Final Test Results ===\")\n",
        "print(f\"Next Day   - Acc: {metrics_day[0]:.4f}, Prec: {metrics_day[1]:.4f}, Rec: {metrics_day[2]:.4f}, F1: {metrics_day[3]:.4f}\")\n",
        "print(f\"Next Week  - Acc: {metrics_week[0]:.4f}, Prec: {metrics_week[1]:.4f}, Rec: {metrics_week[2]:.4f}, F1: {metrics_week[3]:.4f}\")\n",
        "print(f\"Next Month - Acc: {metrics_month[0]:.4f}, Prec: {metrics_month[1]:.4f}, Rec: {metrics_month[2]:.4f}, F1: {metrics_month[3]:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "7a80018c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a80018c",
        "outputId": "5241c866-2a61-4f6c-fad1-f4d4731483e3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.11/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.11/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
            "  self._init_dates(dates, freq)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== ARIMA Baseline (ABBV only) ===\n",
            "Accuracy: 0.8667 | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
            "  return get_prediction_index(\n",
            "/usr/local/lib/python3.11/dist-packages/statsmodels/tsa/base/tsa_model.py:837: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
            "  return get_prediction_index(\n"
          ]
        }
      ],
      "source": [
        "# ARIMA Baseline\n",
        "series = feature_data['ABBV']['Close']\n",
        "train_series = series[:-30]\n",
        "test_series = series[-30:]\n",
        "\n",
        "model_arima = ARIMA(train_series, order=(5,1,0)).fit()\n",
        "forecast = model_arima.forecast(steps=len(test_series))\n",
        "\n",
        "predicted_direction = (forecast.values > train_series.iloc[-1]).astype(int)\n",
        "true_direction = (test_series.values > train_series.iloc[-1]).astype(int)\n",
        "\n",
        "acc_arima = accuracy_score(true_direction, predicted_direction)\n",
        "prec_arima = precision_score(true_direction, predicted_direction, zero_division=0)\n",
        "rec_arima = recall_score(true_direction, predicted_direction, zero_division=0)\n",
        "f1_arima = f1_score(true_direction, predicted_direction, zero_division=0)\n",
        "\n",
        "print(\"\\n=== ARIMA Baseline (ABBV only) ===\")\n",
        "print(f\"Accuracy: {acc_arima:.4f} | Precision: {prec_arima:.4f} | Recall: {rec_arima:.4f} | F1: {f1_arima:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "EJI_9gKDczih",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJI_9gKDczih",
        "outputId": "942e9f3b-d1bd-47fa-e37f-1dcee145be5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Naive Baseline (ABBV only) ===\n",
            "Accuracy: 0.5329 | Precision: 0.5669 | Recall: 0.5669 | F1: 0.5669\n"
          ]
        }
      ],
      "source": [
        "# Naive Baseline\n",
        "true_direction = (series.shift(-1) > series).astype(int).dropna()\n",
        "naive_prediction = (series.shift(0) > series.shift(1)).astype(int).dropna()\n",
        "\n",
        "acc_naive = accuracy_score(true_direction, naive_prediction)\n",
        "prec_naive = precision_score(true_direction, naive_prediction, zero_division=0)\n",
        "rec_naive = recall_score(true_direction, naive_prediction, zero_division=0)\n",
        "f1_naive = f1_score(true_direction, naive_prediction, zero_division=0)\n",
        "\n",
        "print(\"\\n=== Naive Baseline (ABBV only) ===\")\n",
        "print(f\"Accuracy: {acc_naive:.4f} | Precision: {prec_naive:.4f} | Recall: {rec_naive:.4f} | F1: {f1_naive:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
